# Mysql

## Mysql基础

### 1.MySQL出现性能差的原因有哪些？

1.可能使用了全表扫描（要加索引优化）

2.可能查询语句过于复杂，如多表 JOIN 或嵌套子查询（优化查询语句）

3.可能单表数据量过大（进行分表优化）

4.可能热点数据访问量过大（使用Redis进行压力分摊）

### 2.数据库三大范式

1.第一范式：每一列都是不可再细分的基础数据单元

2.第二范式：每一列都和主键直接相关

3.第三范式：非主键列应该只依赖于主键

### 3.varchar和char的区别

varchar是可变数据类型，最多可到65535字符数，因为实际字符集的存在，需要占用2个字符长度，因此可存最多65533

char是不可变数据类型，多出来的空位会以空格填充

### 4.blob和text区别

blob存储二进制数据，例如图片、音频、视频、文件

text存储文本数据，例如日志、评论、文章

### 5.DATETIME和TIMESTAMP的区别

DATETIME直接存储时间的完整值，不考虑时区

TIMESTAMP存储Unix时间戳，考虑时区因素

### 6.in和exists区别

in会先执行子查询，将其加载到内存中再进行外层查询

exists会对外部查询的每一行执行一次子查询，该子查询只关心是否返回行，返回则exist为真，所以不会加载太多数据到内存

如果子查询出现了NULL值，则in条件查询永远不会为真，发生NULL值陷，而exists只要返回行就为真，所以不受NULL值影响

### 7.记录货币用什么类型较好

DECIMAL精确数值类型

float和double是浮点数类型，存在精度问题

### 8.怎么存储emoji

emoji是4个字节的UTF-8字符，而mysql的utf8最多支持3个字节，需要使用utf8mb4

### 9.drop、delete、truncate的区别

drop是物理删除整张表，无法回滚

delete是行级删除，带where条件，可以回滚

truncate 用于清空表中的所有数据，但会保留表结构，不能回滚。

### 10.union和union all区别

union 会去重结果的重复行，union all不会

### 11.count(1)、count(*)、count(列名)区别

count(1)和count(*)无区别，count(列名)会统计列不为NULL的行数

### 12.SQL的查询语句执行顺序

先执行 FROM 确定主表，再执行 JOIN 连接，然后 WHERE 进行过滤，接着 GROUP BY 进行分组，HAVING 过滤聚合结果，SELECT 选择最终列，ORDER BY 排序，最后 LIMIT 限制返回行数。

## 数据库架构

### 13.Mysql基础架构

连接层：负责客户端的连接，包括身份验证、权限校验等

服务层：负责查询解析、优化、执行等操作，binlog就在这一层记录sql语句变化

存储引擎层：负责实际数据的存储，支持InnoDB、MyISAM、Memory

## 14.一条查询语句如何执行的


1.客户端发送 SQL 查询语句到 MySQL 服务器。

2.MySQL 服务器的连接器开始处理这个请求，跟客户端建立连接、获取权限、管理连接。

3.解析器对 SQL 语句进行解析，检查语句是否符合 SQL 语法规则，确保数据库、表和列都是存在的，并处理 SQL 语句中的名称解析和权限验证。

4.优化器负责确定 SQL 语句的执行计划，这包括选择使用哪些索引，以及决定表之间的连接顺序等。

5.执行器会调用存储引擎的 API 来进行数据的读写。

6.存储引擎负责查询数据，并将执行结果返回给客户端。客户端接收到查询结果，完成这次查询请求。

## 事务的全流程：


┌── 事务开始 (START TRANSACTION / 自动开始) ───────────────────────┐
│ undo log记录数据的原来样子做备份
│根据用户的事务代码将变更的数据写入data page中
└──────────────────────────────────────────────────────────────────┘

    ↓ 客户端执行 COMMIT

┌── Prepare 阶段 (InnoDB) ───────────────────────────────────────────┐
│将此次数据变更的信息更新到redolog buffer内存中
│根据设置选择是否立即将redo buffer中的信息立即写入磁盘
│写入之后追加prepare标记
└──────────────────────────────────────────────────────────────────┘

    ↓ 然后 MySQL Server 层处理 binlog

┌── Binlog 写入 + 刷盘 ───────────────────────────────────────────────┐
│ 将本事务的操作 写入 binlog cache / binlog buffer 内存中
│ 根据设置选择是否立即将binlog buffer写入磁盘
└──────────────────────────────────────────────────────────────────┘

    ↓ binlog fsync 成功

┌── Commit 阶段 (InnoDB 完成提交) ───────────────────────────────────┐
│ binlog刷盘之后代表着板上钉钉，此时根据设置可以选择是否将redolog中commit立即替换prepare，也可以为了效率后续批量处理                  │
└──────────────────────────────────────────────────────────────────┘

    ↓ 数据页 (dirty page) 尚未 necessarily 持久化

┌── 后台 / 异步阶段: data page + Undo log cleanup ─────────────────────┐
│同步buffer pool中数据到磁盘，并且清除undo log

──────────────────────────────────────────────────────────────────┘

# Redis

## select/epoll：

#### select:

select是做了三次遍历,两次拷贝，第一次是用户态拷贝到内核态，进程进行第一次遍历看看有没有哪个fd是有数据的，扫描一遍之后发现如果有就标记之后拷贝回用户态，没有的话进程就进入阻塞等待。第二次是当有数据到达socket缓冲区的时候，会唤醒select进程，再次扫描一遍找到有数据的fd标记并拷贝回用户态。第三次用户态扫描一遍找出有标记的fd进行数据处理。

#### epoll

先内核态epoll_create创建一个epoll对象，也就是建立一颗红黑树，同时建立就绪链表，当有socket连接，用户态调用epoll_ctl触发系统调用，内核通过用户传入的 fd 找到对应的内核 Socket 对象，将该 Socket 对象插入 epoll 红黑树；同时给这个 Socket 注册 epoll 的回调函数。这个时候，当没有数据到达socket的时候，用户态epoll_wait函数是进行睡眠阻塞状态。当有数据的时候，这个时候会触发socket的回调函数找到他所在的epoll实例（包含红黑树以及就绪链表），然后将这个socket的事件信息加入到就绪链表中，将链表拷贝给用户态的events数组，然后唤醒用户态的睡眠状态开始遍历数组处理事件

## 持久化

#### AOF

![1765530867283](image/八股文/1765530867283.png)

#### RDB

![1765534174813](image/八股文/1765534174813.png)

RDB他是主进程fork一个子进程出来（这一步是阻塞的），子进程创建完成之后会结束阻塞，然后会将复制的数据快照写入磁盘中，写完之后这个子进程结束，完成一轮持久化。但是这个时候主进程可能在子进程刷盘的时候有新的数据写进来，这时候内存中的这页内存数据就会被复制一份（但是在同一内存下），主进程仍然往内存数据里面写，但是子进程会对备份的那个内存数据进行刷盘。因为主进程还在这个期间有数据写入内存，导致持久化磁盘中的数据不是最新的，这时候可以根据系统配置设置RDB间隔又要开启下一轮RDB过程了。可以通过save和bgsave来手动触发RDB持久化操作。自动触发：redis.conf配置文件设置 `save <seconds> <changes>`（可多次）来设置触发条件。

#### 混合持久化

这一步针对重写步骤来说的。混合持久化的核心是：**“触发重写→fork 子进程写 RDB 全量→主进程缓存增量到 aof_rewrite_buf→子进程写完 RDB 后，主进程补写 aof_rewrite_buf→替换旧文件”，混合持久化的 RDB 部分，是写在**新的临时 AOF 文件**开头，不是直接写入旧的 AOF 文件。	**

#### Mysql和Redis数据一致性

### 1.旁路缓存+binlog+canal方案（最流行的方案）

1. 读数据时先查缓存，缓存没有则去数据库中读然后填回缓存；
2. 写数据时先改数据库，MySQL 改数据自动写 binlog 日志；
3. Canal 伪装成 MySQL 从库，读取并解析 binlog，把mysql更新数据的消息发到 Kafka；
4. 专门的「缓存消费服务」一直盯着 Kafka，拿到这条消息后，主动调用 Redis 的删除命令，删掉该数据的缓存；
5. 若 Redis 正常，删缓存成功，若不正常，则redis过期时间作为兜底删除

#### 2.延迟双删

先删缓存，再删数据库，再删一遍缓存。因为如果只第一次删缓存而后续不删的话，会导致更新数据库的时候其他线程进来并发读数据的时候，找缓存发现没有，于是将数据库的未更新完的旧数据拿来写到缓存中，等数据库更新完导致数据不一致，于是要第二次删除。
