# 1.为什么要选择这个项目来做？

**我选择做这个电商评价系统项目主要基于几个因素来考虑的**

1.首先我觉得这个系统项目更加贴近互联网公司真实的业务场景，

像淘宝、京东、美团都有类似系统.

涉及C端用户、B端商家、O端运营三端协作，业务复杂度高，能学到完整的业务闭环.

包含评价创建、审核、回复、申诉等完整流程，跟真实生产环境很接近.

2.其次我认为这个项目的挑战性比较强，

评价系统的核心是 **高并发查询** ，

在真实场景下比如用户搜索商品评价、*按关键词筛选*，日均可能百万级查询

我学习了 **CQRS读写分离架构！！！！！！**

但是传统的MySQL主从架构在模糊搜索（LIKE %）场景下会索引失效，从库压力巨大

然后使我学习了 **CQRS读写分离架构** 的进阶方案，

用MySQL保证写一致性，用ES做复杂查询，用Redis缓存热数据.

3.这个项目涉及的主流技术栈比较全面

* 这个项目让我系统性地学习了 **微服务架构** ：服务拆分、RPC调用
* 掌握了 **数据同步方案** ：Canal监听binlog + Kafka解耦 + 消费端同步ES
* 我也实现了 **高并发优化方案** ：Redis缓存 + Singleflight防击穿 + ES倒排索引
* 用到了Go生态的主流框架：Kratos、Gorm、Wire等

# 2.这个项目的业务流程是什么

**我的评价系统涉及三端（C端用户、B端商家、O端运营），**

用户下单购物
→ 订单完成后可以评价
→ 填写评分（1-5星）、评价内容、上传图片/视频
→ 提交评价
→ 评价进入待审核状态（status=10）（可以被查到）

运营人员登录后台
→ 查看待审核评价列表
→ 审核内容是否违规（广告、辱骂等）
→ 审核通过（status=20）或不通过隐藏（status=40），

并且标记这个评论为已审核
→ 审核通过的评价继续展示在商品详情页

商家登录后台
→ 查看自己商品的评价列表
→ 对评价进行回复（比如感谢好评、解释问题）
→ 如果认为评价不实，可以发起申诉

运营审核商家的申诉
→ 申诉通过：隐藏该评价（status=40）
→ 申诉拒绝：评价继续展示，并且将这个回复标记已审核

# 3.用户创建评价的详细流程是什么，又哪些校验

用户创建评价的流程有参数校验、业务校验和数据持久化的过程

**1.参数校验（service层），**使用了Proto的validate自动校验，比如userID必须大于0，评分要在1-5之间，

校验失败直接返回400错误。

2.**业务校验（Biz层）**，例如检查订单是否已评价（防止重复评价），

生成雪花ID，然后设置待审核状态 Status=10。

3.**持久化（Data层），**写入MySQL，成功后自动产生Binlog，Canal监听到变更，发送到Kafka，

review-job消费并同步到ES。

# **4.如何保证数据一致性的**

比如商家回复评价涉及两张表的更新，我用数据库事务保证一致性。

因为我这个项目针对这个问题做了两个事情

1.商家回复需要往回复表中插入一条回复记录

2.用户评价表的回复状态字段更新为1

如果第一步成功第二步失败了的话，就会出现：回复表有数据，

但评价表回复字段还是0，显示未回复，这样的话用户就看不到商家的回复了。

所以我就用了数据库的事务来保证这个事情，

首先要进行简单的业务校验，比如不能回复已经回复过的评价，

不能水平越权回复别人评价。

然后进行事务操作，先将回复记录插入回复表，失败自动回滚，

然后将回复的状态值插入评价表，失败也自动回滚。

# 5.MySQL和ES之间是如何保证数据一致性的

你的项目场景：**用户创建评价 → 写入 MySQL → 同步到 ES，**

我用的是 **Canal + Kafka 方案，**

1. **首先是通过MySQL 的 binlog 来保证数据一致性**
   比如用户创建评价，写入 MySQL

   MySQL 会自动产生 binlog（数据变更日志）

   **只要 MySQL 事务提交成功，binlog 就一定会产生**
2. **Canal 监听 binlog 并发送到 Kafka**

   * Canal 伪装成 MySQL 的从库，实时读取 binlog
   * 把 binlog 变更发送到 Kafka
   * **Kafka 的持久化保证消息不丢失**
3. **review-job 消费 Kafka 并写入 ES**

   * review-job 从 Kafka 拉取消息
   * 使用评价 ID 作为 ES 文档 ID 写入（保证幂等）
   * **即使重复消费，ES 也只有一份数据**

# 6.**Canal是怎么监听MySQL的binlog的**

Canal伪装成MySQL的从库，通过MySQL主从复制协议获取binlog，

这个原理和MySQL的主从复制原理差不多，

MySQL的主从复制原理是：

主库 → 产生binlog → 从库拉取binlog → 从库按照binlog回放

Canal的做法：

主库 → 产生binlog → Canal伪装成从库 → 解析binlog → 发送到Kafka

# 7.**如果Canal挂了，数据会丢吗？**

不会丢失，因为MySQL的binlog会保留，

Canal挂了之后，MySQL继续产生binlog，

binlog文件保存在磁盘上（默认保留7天），

Canal会记录消费位置，Canal的meta.dat文件记录binlog的position信息，

Canal恢复后，从上次的位置继续消费，

他会先读取meta.dat，从上次的position继续消费，不会重复也不会丢失

但是在Canal挂了期间，ES没有最新的数据（读数据可能查不到最新数据），

于是用户查不到刚写入的评价，商家也查不到刚回复的评价，

我针对这个问题采用的是降级到Mysql，就是先走redis发现找不到，

去ES中找，发现也找不到，就去MySQL中找，虽然慢了一点，但至少保证能查到数据。

# 8.Redis的过期时间是怎么设置的

在我这个项目中，我方便学习统一设置的是10秒，

但是在实际生产环境下，要根据不同商品的热度动态调整，

热门商品：1小时

一般商品：10分钟

冷门商品：1分钟

对于一些一直热门的商品可以设置异步刷新的策略，永不过期。

因为一直热门的商品他的访问量一直是很高的，如果过期了，

缓存击穿会导致大量请求打到MySQL中，数据库压力还是很大的。

或者可以给那些比较热门的商品添加随机偏移的策略（防止雪崩），就是过期时间加随机值。

# 9.为啥要选kafka作为消息队列

1.我的项目选用 Kafka 作为消息队列确实是考虑了一些因素，

首先我查了资料，了解到Kafka 支持高吞吐量场景，

很适合电商评论这种高并发场景。

2.kafka有持久化和分区副本机制，保证消息不丢失，系统可靠性高。

3.Kafka 与其他的模块兼容性好，

比如我们用 Canal+Kafka 实现 MySQL 到 Elasticsearch 的数据同步，

这在业界是主流方案，RabbitMQ 和 RocketMQ 在这方面支持有限。

4.Kafka 社区活跃，文档丰富，横向扩展都很方便，

适合我们这种需要横向扩展的场景。

rabbitMQ他与一些大数据生态集成性不如kafka方便，

而且RabbitMQ吞吐量有限，不适合我们这种高并发电商场景，

RocketMQ虽然吞吐量高，但是但生态和兼容性不如kafka，

5.kafka缺点就是他的消息延迟略高rabbitMQ，但是对于我们这种

实时性要不高的评价系统而言可以接受。

综合考虑，Kafka 是最适合我们项目的消息队列选型

# 10.什么是CQRS架构？

简单来说他就是读写分离的设计模式，写数据走主库，读数据走从库，从库和主库之间

可以通过binlog进行主从同步。

因为传统架构的话，写和读都走主库，而我这个系统他写评价的并发量要远小于

用户或者商家查看评价的并发量，因此读多写少的场景下，要进行主从设计。

# 11.在这个项目中的遇到的困难是什么，怎么解决的

1.**我遇到的一个问题是，做高并发查询的时候会导致数据库压力过大。**

最开始我用的是MySQL主从架构做读写分离，

我设计完这种架构之后，我查阅了资料发现模糊查询可能会产生性能问题，

我这个评价系统支持用户按关键词搜索（比如"质量"这样的关键字），

这种需求在SQL里需要用 `LIKE '%关键词%'` 实现的，

**然后，我设计了一个实验想要验证这个猜想** ：

使用Go脚本批量插入了10万条评价数据，

每条评价包含：用户ID、商家ID、评价内容（100-200字）、评分等，

模拟了3个商家，每个商家3万+评价，

插入了2万条回复数据和5000条申诉数据，

数据规模虽然不如生产环境，但我认为能够暴露一些问题。

然后我开启了MySQL的慢查询日志，long_query_time =0.5 超过500ms就记录，

我分别试了三种查询方式：

1. 精准查询（只用索引字段）：
   SELECT * FROM review_info WHERE store_id = 10001 LIMIT 10;
2. 前缀模糊查询：
   SELECT * FROM review_info WHERE content LIKE '质量%';
3. 全模糊查询：
   SELECT * FROM review_info WHERE content LIKE '%质量%';
   → 响应时间：600-1200ms（全表扫描）

对于全模糊查询然后我通过EXPLAIN分析执行计划，

-type: ALL（全表扫描）

-rows: 100000（扫描10万行）

发现果然是LIKE '%关键词%'这种模糊查询导致索引失效，变成了全表扫描。

**而且另一个问题是商家查看评价时需要关联三张表**（评价表+回复表+申诉表），

这样也会给从库增加负担。

（压测）

*我用JMeter做了简单的压测：*

- *并发用户：100（模拟100个商家同时查询）*
- *每个用户执行10次带模糊搜索的查询*

*结果：*

- *平均响应时间：1.2秒，和我之前explain发现的响应时间差不多，*
- *我的电脑CPU使用率飙到60%（只是i5处理器），*
- *MySQL慢查询日志里记录了大量超过500ms的查询*

*虽然这不是生产级别的压测，但已经能明显看出性能问题。*

**解决方案！！！！！！！！！**

所以我参考了一些开源社区项目的架构方案，采用进阶版的CQRS读写分离架构：
写操作：继续用MySQL保证事务一致性
 读操作：

- 热数据（高频查询）：走Redis缓存，响应时间降到毫秒级
- 冷数据（复杂查询）：走Elasticsearch，利用倒排索引做全文检索
  数据同步是通过Canal监听MySQL binlog → Kafka → review-job消费写入ES

（压测）

**然后优化后我再次用JMeter进行相同测试，我记得当时ES响应时间100ms左右，**

CPU使用率也降了很多，百分之多少我忘记了。这就说明这个之前的方案在我这个项目场景下，

尤其是高并发下确实存在问题。

**2.还有一个问题是缓存击穿的问题。**

假设有1万个并发请求查同一个商家的评价，

Redis中恰好没有这个key（缓存过期或冷启动），

1万个请求同时打到ES，导致ES压力骤增甚至崩溃。

所以我采用的解决方案就是使用Singleflight合并相同请求：

假设1万个相同key的并发请求，那么只有1个请求真正查ES，

其他9999个请求等待并复用第一个请求的结果。ES压力就会降低。

**3.还有就是Mysql和ES的数据同步延迟的问题。**

用户在review-service创建了一条评价（写入MySQL），
Canal监听binlog → Kafka → review-job消费 → 写入ES，
这个链路可能需要几百毫秒甚至几秒，
如果用户立刻去查询，ES中还没有数据，产生"数据丢失"的错觉。

所以我当时采用的方案是，
 创建评价后，返回reviewID给用户
 用户查询详情时，优先查MySQL（用reviewID精确查询，有索引很快）
 列表查询才走ES（用户不会立刻去刷新列表，有时间让数据同步）

我后续的话打算做一个长期优化策略：
监控Kafka消费延迟，设置告警信息lag，

如果 lag 一直在增长，说明有积压，
增加review-job的消费者数量

**4.还有就是分布式ID的生成问题**

这几个微服务都需要生成全局唯一的ID（reviewID），

如果用MySQL自增ID，分库分表后会重复，

如果用UUID，36字节太长，存储浪费，

而且无序不利于索引，不适合做主键索引，

"UUID完全无序，这就会导致MySQL B+树索引频繁页分裂，
    而雪花ID是递增的，新数据总是追加到索引末尾，
    避免了页分裂问题"

后来我采用了雪花算法生成ID的方法解决了。

**5.还有一些比较小的问题**

第一次部署Canal时遇到的坑：
Canal连不上MySQL：权限问题，
 Canal监听不到binlog：MySQL的binlog没开启，
 Kafka消息格式解析错误：不熟悉Canal的JSON格式，

# 12.为什么要设计redis+singleflight这种模式

singleflight是go语言的一个库，

解决的是短时间合并请求，解决大并发的问题。

如果只有redis+ES的话，会出现比如1w个请求，

然后缓存没有造成击穿，导致全部请求打到ES造成崩溃。

那用Singleflight就相当于先让第一个请求查看缓存，

redis中没有的话，放行一个请求到ES拿数据返回给redis，

然后redis再把这个数据返回给剩下的所有请求。

# 13.kratos框架开发流程是什么

嗯，好的。其实我用我项目里"用户创建评价"这个功能来给你讲吧。

【第1步：定义接口（proto文件）】
首先，我得在 api/review/v1/review.proto 里面定义这个接口，

就是说明一下前端要传什么参数给我（userID、orderID、score这些），

我要返回什么（reviewID）。然后框架它能自动帮我生成

HTTP 和 gRPC 两种方式的代码，

我就不用手写路由了，这样挺省事儿的。

【第2步：实现 Service 层】
我在里面写一个方法，这个方法的作用就是接收前端的请求，

然后我调用下面的业务层，再把结果返回给前端。

【第3步：写业务逻辑（Biz层）】
然后真正的业务逻辑我在 biz层 里面写。

比如说，我要检查这个订单有没有被评价过，

如果已经评价过了，就不能再评价，这就是业务规则嘛。

还有生成一个评价 ID，用的是雪花算法。

这些都属于业务逻辑，我觉得这样分开的好处就是，

万一需求改了，我只需要改这一层，其他层不用动。

【第4步：数据访问（Data层）】
最后，我需要把这个评价存到数据库里，

这就是 Data 层的工作了。我在里面写了一个方法，

就负责把数据存到 MySQL。或者查询数据走redis+ES。

【第5步：配置服务器（Server）】
然后我还要配置一下 HTTP 和 gRPC 的服务器。

【第6步：依赖注入（Wire）】
奥对，最后一步就是用 Wire 这个工具做依赖注入。

比如就是我有一堆类，它们之间有依赖关系，

比如 Service 依赖 Biz，Biz 依赖 Data。

然后在wire.go 里面声明一下依赖，然后执行 wire 命令，

它就自动生成代码了。

# 14.k8s了解多少

"我的项目中有四个微服务，

原本分别部署在三台电脑上。

后来想尝试实现一下分布式集群方案，

好处是一个服务挂了，不会整体挂掉，高可用，

而且服务发现可以解决每次我手动改IP的问题，

他会自动找到可用的pod，然后pod挂的话他也会自动重启。

Pod 就是 K8s 里最小的部署单位，可以把它理解成一个 **“迷你小服务器”**。

# 15.gRPC他是如何定义的

它基于 Google 的 HTTP/2 协议，并使用 Proto Buffer作为数据协议，

相比 HTTP/1，HTTP/2 它是二进制协议，比文本协议更高效；

支持  **多路复用** ，也就是一个连接上可以并行发送多个请求，

减少了传统 HTTP 协议中的连接开销；另外，它有  **头部压缩** ，

减少了请求和响应的大小，从而提高了网络传输的效率。

# 16.gRPC和http使用在什么场景下

rpc调用发生在微服务之间的函数调用过程中，http是用于和前端交互场景下。

grpc提供了更高效的、低延迟的服务间调用。而前端浏览器不直接支持 gRPC，

如果前端需要与 gRPC 服务交互，可以使用 **gRPC-Web** 这种技术，

它通过 HTTP 协议与浏览器兼容，并通过代理转发请求给后端的 gRPC 服务，

**HTTP** 通常使用 **JSON** 格式，JSON 在浏览器中有原生的支持，

且易于与 JavaScript 进行交互。因此，前端开发者通常更倾向于

使用**JSON** 格式的数据进行请求。

对于grpc来说，protobuf 的数据序列化与反序列化速度非常快，

gRPC 可以实现更低的通信延迟，对于需要高性能、高吞吐量的服务间通信是很重要的。

gRPC 支持  **多种编程语言** （包括 C++, Java, Go, Python, Ruby, Node.js 等），

并且通过 protobuf 可以自动生成客户端和服务器端的代码。

这使得不同技术栈之间的微服务能够高效地进行通信。

虽然 **HTTP/REST** 也有跨语言的支持，但是 **gRPC通过 `.proto` 文件自动生成代码，**

**这样会减少了跨语言通信的出错几率。**

# 自我介绍

面试官您好，我是周泽华。

我现在就读东南大学电子信息专业，目前是研二，

对后端开发特别感兴趣，我主要做过一个电商评价系统的项目。

评价服务是可以为公司电商业务提供了用户评价相关功能。

整个评价服务包含 C、B 端和 O 端三部分，涉及 C 端用户发表评价，

O 端运营审核评价以及 B 端商家查看 / 回复评价等主要业务流程。

涉及 MySQL、Redis、Elasticsearch、canal、Kafka 等多个组件。

就是我针对**高并发查询**做了一套CQRS架构：

然后数据同步这块，我用了 Canal + Kafka 的组合，
然后 review-job 这个微服务去消费消息并同步到 Elasticsearch。

通过这个项目，我理解了 CQRS 架构、分布式缓存、微服务通信这些概念，
也学会了用 Kratos 框架。

~~我了解到贵公司也有处理留言或弹幕评论这种高并发的场景，~~

我认为我如果有机会也能够学到更多知识。
